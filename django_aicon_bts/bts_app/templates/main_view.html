<!DOCTYPE html>
<html>
<head>
    <title>Image Generator</title>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>
<body>
    <form id="image-form">
        {% csrf_token %}
        <input type="text" id="image-prompt" placeholder="Enter image prompt">
        <button type="submit">Generate Image</button>
    </form>
    
    <div id="mic_recording">
        <button id="startRecording">Start Recording</button>
        <button id="stopRecording" disabled>Stop Recording</button>
    </div>
    <div id="loading-transcription" style="display: none;">
        <p>Transcribing...</p>
    </div>
    <div id="transcriptionResult"></div>
    <div id="loading-gpt-prompt" style="display: none;">
        <p>Generating GPT prompt...</p>
    </div>
    <div id="gptPromptResult"></div>
    <div id="loading-image" style="display: none;">
        <p>Generating image...</p>
    </div>
    <img id="generated-image" src="" alt="Generated image will appear here">

    <script>

        function getGptContextPrompt(speech2text) {
                $.ajax({
                    url: '/get_gpt_context_prompt/',
                    type: 'post',
                    data: {
                        'result_speech2text': speech2text,
                        'csrfmiddlewaretoken': $('input[name=csrfmiddlewaretoken]').val(),
                    },
                    success: function(data){
                        console.log(data);
                        console.log('GPT response received successfully');      
                        $('#gptPromptResult').text(data);   
                        onGptPromptResultReady();
                        generateImage(data);
                    }
                });
            }


        function generateImage(imagePrompt) {
                $.ajax({
                    url: '/generate_image/',
                    type: 'post',
                    data: {
                        'image_prompt': imagePrompt,
                        'csrfmiddlewaretoken': $('input[name=csrfmiddlewaretoken]').val(),
                    },
                    success: function(data){
                        $('#generated-image').attr('src', data);
                        console.log(data);
                        console.log('Image generated successfully');
                        onImageGenerated();
                    }
                });
            }


        $(document).ready(function(){  
            // Initially, hide all elements except the mic_recording
            $('#image-form, #loading-transcription, #transcriptionResult, #loading-gpt-prompt, #gptPromptResult, #loading-image, #generated-image').hide();
            $('#mic_recording').show();            

            $('#image-form').on('submit', function(e){
                e.preventDefault();
                const imagePrompt = $('#image-prompt').val();
                getGptContextPrompt(imagePrompt);
                generateImage(imagePrompt);
            });
        });

        $('#startRecording').click(function() {
            // When the user starts recording, hide all elements except the mic_recording
            $('#image-form, #loading-transcription, #transcriptionResult, #loading-gpt-prompt, #gptPromptResult, #loading-image, #generated-image').hide();
            $('#mic_recording').show();
        });

        $('#stopRecording').click(function() {
            // When the user stops recording, show only the loading-transcription
            $('#mic_recording, #image-form, #transcriptionResult, #loading-gpt-prompt, #gptPromptResult, #loading-image, #generated-image').hide();
            $('#loading-transcription').show();
        });

        // When the transcription result is ready, show only the loading-gpt-prompt
        // You need to call this function when the transcription result is ready
        function onTranscriptionResultReady() {
            $('#mic_recording, #image-form, #loading-transcription, #loading-image, #generated-image').hide();
            $('#transcriptionResult, #loading-gpt-prompt').show();
        }

        // When the GPT prompt result is ready, show only the gptPromptResult and loading-image
        // You need to call this function when the GPT prompt result is ready
        function onGptPromptResultReady() {
            $('#mic_recording, #image-form, #loading-transcription, #transcriptionResult, #loading-gpt-prompt, #generated-image').hide();
            $('#gptPromptResult, #loading-image').show();
        }

        // When the image is generated, show only the generated image
        // You need to call this function when the image is generated
        function onImageGenerated() {
            $('#mic_recording, #image-form, #loading-transcription, #transcriptionResult, #loading-gpt-prompt, #gptPromptResult, #loading-image').hide();
            $('#mic_recording, #generated-image').show();
        }

    

        document.addEventListener('DOMContentLoaded', () => {
            const startRecordingButton = document.getElementById('startRecording');
            const stopRecordingButton = document.getElementById('stopRecording');

            let mediaRecorder;
            let audioChunks = [];

            async function startRecording() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream);

                    mediaRecorder.ondataavailable = event => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                        }
                    };

                    mediaRecorder.onstop = () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });

                        const formData = new FormData();
                        formData.append('file', audioBlob);

                        // Send the recorded audio to the Django server
                        fetch('/process_audio/', {
                            method: 'POST',
                            body: formData,
                        })
                        .then(response => response.json())
                        .then(data => {
                            console.log('Transcription:', data.transcript);
                            //update the transcription result in the transcriptionResult div
                            $('#transcriptionResult').text(data.transcript);

                            onTranscriptionResultReady();

                            getGptContextPrompt(data.transcript);

                            // Use the transcription as the image prompt
                            //generateImage(data.transcript);
                        })
                        .catch(error => {
                            console.error('Error:', error);
                        });
                    };

                    startRecordingButton.disabled = true;
                    stopRecordingButton.disabled = false;
                    audioChunks = [];
                    mediaRecorder.start();
                } catch (error) {
                    console.error('Error starting recording:', error);
                }
            }

            function stopRecording() {
                if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                    mediaRecorder.stop();
                    startRecordingButton.disabled = false;
                    stopRecordingButton.disabled = true;
                }
            }

            startRecordingButton.addEventListener('click', startRecording);
            stopRecordingButton.addEventListener('click', stopRecording);
        });
    </script>
</body>
</html>